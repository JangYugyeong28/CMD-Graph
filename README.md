# Generating Command Modeling and Design Graphs with Data Augmentation for Enhanced 3D Modeling Support

<img width="595" height="250" alt="Figure1" src="https://github.com/user-attachments/assets/87d7da6a-f9e2-4849-bb5f-df9caca59d6e" />

[[ScienceDirect]](https://www.sciencedirect.com/science/article/abs/pii/S1474034625005373)  
**Authors:** [Yugyeong Jang](https://yugyeong.cargo.site/) Â· [Kyung Hoon Hyun](https://designinformatics.hanyang.ac.kr/People_Kyung-Hoon-Hyun)

---

## ğŸ” Overview

This repository provides the **inference and post-processing code for extracting modeling command sequences** from 3D shapes.

Built on top of the original **shape2prog** pipeline, this code:

- decodes voxel shapes into a **domain-specific language (DSL)** program,
- converts the DSL into **Rhino-style modeling commands**, and
- optionally renders **reconstructed meshes and per-step sequence images**.

> ğŸ“ This repository focuses on **modeling sequence extraction only**.  
> It does **not** include training code or dataset distribution, and it does **not** build CMD-Graph structures.

---

## ğŸ—‚ What This Repository Provides

This repo includes:

- âœ… **Modified test script (`test_copy.py`)**
  - Loads a trained shape2prog model
  - Decodes voxel shapes into programs (DSL)
  - Optionally saves:
    - DSL text files (`programs/`)
    - Converted Rhino command files (`rhino_commands/`)
    - Reconstructed model images (`images/`)
    - Step-by-step sequence images (`sequence_images/`)

- âœ… **Example shell command** for running creative design / inference

This repo **does not** provide:

- âŒ Training code for the program generator  
- âŒ The original datasets used in training  
- âŒ CMD-Graph construction code

Instead, it focuses on:

> **â€œGiven 3D shapes (from a trained shape2prog model), how do we extract and save the corresponding modeling command sequences?â€**

---

## ğŸ“¦ Depends On: shape2prog

We build directly on:

- **shape2prog (Huang et al.)**  
  ğŸ”— https://github.com/HobbitLong/shape2prog

In our setup:

- We follow the **same dataset configuration and training pipeline** as shape2prog.
- Voxel shapes are upsampled to **64Ã—64Ã—64** for training and decoding.
- The trained model checkpoint is then used by `test_copy.py` to generate programs.

Because of licensing and size constraints, we do **not** re-distribute:

- the original datasets  
- the full training code / checkpoints

Please follow the original shape2prog repository for:

- dataset preparation  
- training instructions  
- baseline testing scripts

---

## ğŸš€ Usage Guide â€” Modeling Sequence Extraction

Once you have shape2prog installed, trained, and your checkpoint ready,  
you can run the **creative design / decoding step** using the modified test script.

### 1ï¸âƒ£ Example: run `test_copy.py` for sequence extraction

```bash
CUDA_VISIBLE_DEVICES=0 python test_copy.py \
  --model /home/donut/YG_BABO/shape2prog/model/ckpts_program_generator_828/ckpt_epoch_40.t7 \
  --data  /home/donut/YG_BABO/shape2prog/data_test/test/data.h5 \
  --batch_size 64 \
  --save_path ./output/yg_test/ \
  --save_prog \
  --save_img
```bash

### 2ï¸âƒ£ Outputs

After running the command above, the following folders are created under `--save_path`:

ğŸ“ programs/
â””â”€ Decoded DSL programs inferred from the model
e.g., 0.txt, 1.txt, ...

ğŸ“ rhino_commands/
â””â”€ Rhino-style modeling command sequences converted from DSL
e.g., 0_rhino.txt, ...

ğŸ“ images/
â””â”€ Single-view rendered images of the reconstructed 3D shapes

ğŸ“ sequence_images/
â””â”€ Per-step sequence execution screenshots from execute_shape_program_with_trace
e.g., sample_0/step_0.png, sample_0/step_1.png, ...


These files together form the **modeling sequence dataset**, which can be used for further:

âœ” analysis  
âœ” visualization  
âœ” workflow modeling research  
âœ” UI / modeling support systems

