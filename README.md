# Generating Command Modeling and Design Graphs with Data Augmentation for Enhanced 3D Modeling Support

<img width="2481" height="1021" alt="figure1" src="https://github.com/user-attachments/assets/38b76d8c-8dac-4858-a88f-616aacbc72b2" />

## 
[[ScienceDirect]](https://www.sciencedirect.com/science/article/abs/pii/S1474034625005373  ) <br>
[Yugyeong Jang](yugyeong.cargo.site), [Kyung Hoon Hyun](https://designinformatics.hanyang.ac.kr/People_Kyung-Hoon-Hyun)


# Introduction
This study proposes a system that automatically generates 3D modeling sequences for various 3D shapes. Existing 3D modeling systems impose a high cognitive load on users, making it particularly difficult for beginners to approach. To address this issue, we developed a system that applies a method for inferring and extracting modeling sequences from 3D shapes to generate Command Modeling and Design Graphs without the need for additional modeling data collection. For this purpose, we reconstructed geometric elements and their structural relationships using a domain-specific language, efficiently modeling shape repetitions and symmetries. The proposed system infers modeling sequences from completed 3D models and converts them into workflow graphs, providing richer and more detailed sequence data compared to existing datasets. As a result, users are expected to significantly improve design efficiency through intuitive modeling processes and command support.

# UPDATES

- 


# âœ¨ Key Features

### ğŸ”¹ 1. Text-Conditional Part-Level Editing
- Shape edits based on adjectives (e.g., open, curved, thin)
- LLM outputs modified extrinsic latents for 16 Gaussian blobs

### ğŸ”¹ 2. Exploration Map (UMAP)
- Visualizes large-scale 3D design space (~58k chairs)
- Differentiates user-generated vs. LLM-generated vs. ROI-region samples

### ğŸ”¹ 3. Bayesian ROI Inference
- Identifies user interest regions based on recent selections

### ğŸ”¹ 4. Design Versioning Tree
- Hierarchical visualization of all variations and their parentâ€“child relationships


---

# ğŸ¯ Text-guided latent editing & Generation with Fine-tuned Model

GenPara supports fine-tuning using extrinsic latent vectors generated by [SALAD](https://github.com/KAIST-Visual-AI-Group/SALAD). <br>
Please use ready-to-use data and pre-trained SALAD and SPAGHETTI checkpoints [[here]](https://github.com/KAIST-Visual-AI-Group/SALAD). 
<div align="center">
  <img src="https://github.com/user-attachments/assets/6e867b57-7d72-452f-ae1f-82dd96c004da"
       alt="test_gaussian_rotation"
       width="200" />
</div>

### 1. Prepare Extrinsic Latent Files
Each model should contain:
- 16 Gaussian blobs
- Each blob: 16 parameters (Mu, eigenvectors, Pi, eigenvalues)

Example JSON files in:
```
dataset/GenPara_finetuningDataset_chairs.jsonl/
```

### 2. Create Fine-tuning Dataset (JSONL)
Each record must contain:
- System instruction
- User request describing parts + adjectives
- Assistant output providing adjusted extrinsic latents
  
```
code/genpara_system_instruction.txt/
```

### 3. Fine-tune Model
Use OpenAI fine-tuning API:
```
openai api fine_tuning.jobs.create -t dataset/GenPara_finetuningDataset_chairs.jsonl -m gpt-3.5-turbo-1106
```

### 4. Deploy Fine-tuned Model
Model returns full extrinsic latent vectors suitable for reconstruction.
```
code/genpara_text_guided_chair_edit.py
```

# ğŸ—ºï¸ Frontend (Exploration Map & Versioning Tree) 

to be appear


---

# ğŸ“š Citation

```
@article{jang2025generating,
  title={Generating command modeling and design graphs with data augmentation for enhanced 3D modeling support},
  author={Jang, Yugyeong and Hyun, Kyung Hoon},
  journal={Advanced Engineering Informatics},
  volume={68},
  pages={103644},
  year={2025},
  publisher={Elsevier}
}

```

---

# ğŸ™Œ Acknowledgements

